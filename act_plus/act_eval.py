import importlib
import numpy as np
import yaml
from PIL import Image
from tqdm import tqdm
from pprint import pprint
import argparse
import pathlib
import matplotlib.pyplot as plt
import os
import gc

# RLBenchç›¸å…³æ¨¡å—
from rlbench.action_modes.action_mode import MoveArmThenGripper
from rlbench.action_modes.arm_action_modes import EndEffectorPoseViaPlanning
from rlbench.action_modes.gripper_action_modes import GripperJointPosition
from rlbench.environment import Environment
from rlbench.observation_config import ObservationConfig

# å¯¼å…¥ACTç­–ç•¥å°è£…ç±»
from act_policy_wrapper import ACTPolicyWrapper


class RLBenchACTController:
    """
    ä½¿ç”¨ACTç­–ç•¥æ§åˆ¶RLBenchç¯å¢ƒä¸­æœºå™¨äººçš„æ§åˆ¶å™¨ç±»
    """
    
    def __init__(self, act_config_path):
        """
        åˆå§‹åŒ–æ§åˆ¶å™¨
        
        Args:
            act_config_path: ACTé…ç½®æ–‡ä»¶è·¯å¾„
        """
        # åŠ è½½ACTé…ç½®
        with open(act_config_path, 'r') as f:
            act_config = yaml.safe_load(f)
            
        # åˆå§‹åŒ–ACTç­–ç•¥å°è£…
        self.act_policy = ACTPolicyWrapper(act_config.get('act_policy'))
        
        # å­˜å‚¨ç¯å¢ƒå’Œä»»åŠ¡ç›¸å…³å˜é‡
        self.env = None
        self.task = None
        self.camera_names = act_config.get('cameras')
        # ç§»é™¤ç‰¹å®šæœºå™¨äººè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
        self.robot_setup = None
        self.image_width = act_config.get('image').get('width')
        self.image_height = act_config.get('image').get('height')
        
        # ç”¨äºä¿å­˜å…³èŠ‚ä½ç½®æ•°æ®çš„å­—å…¸
        self.joint_data = {
            'current': [],  # å½“å‰å…³èŠ‚ä½ç½®
            'target': []    # ç›®æ ‡å…³èŠ‚ä½ç½®
        }
    
    def create_observation_config(self):
        """åˆ›å»ºRLBenchè§‚å¯Ÿé…ç½®"""
        obs_config = ObservationConfig()
        
        # ç›¸æœºé…ç½®æ˜ å°„
        cameras_dict = {
            'front_camera': obs_config.front_camera,
            'wrist_camera': obs_config.wrist_camera,
            'left_shoulder_camera': obs_config.left_shoulder_camera,
            'right_shoulder_camera': obs_config.right_shoulder_camera,
            'overhead_camera': obs_config.overhead_camera
        }
        
        # å…ˆç¦ç”¨æ‰€æœ‰ç›¸æœº
        for camera in cameras_dict.values():
            camera.rgb = False
            
        # å¯ç”¨æŒ‡å®šçš„ç›¸æœº
        for camera_name in self.camera_names:
            if camera_name in cameras_dict:
                cameras_dict[camera_name].rgb = True
                cameras_dict[camera_name].image_size = (self.image_width, self.image_height)
                print(f"å¯ç”¨ç›¸æœº: {camera_name}")
        
        # å¯ç”¨å¿…è¦çš„ä¼ æ„Ÿå™¨
        obs_config.joint_positions = True
        obs_config.joint_velocities = True
        obs_config.gripper_open = True
        obs_config.gripper_pose = True  # å¯ç”¨æœ«ç«¯ä½å§¿
        obs_config.gripper_joint_positions = True
        obs_config.gripper_matrix = True
        
        return obs_config
    
    def setup_environment(self):
        """è®¾ç½®å¹¶å¯åŠ¨RLBenchç¯å¢ƒ"""
        # åˆ›å»ºè§‚å¯Ÿé…ç½®
        obs_config = self.create_observation_config()
        
        # æ‰“å°é…ç½®ä¿¡æ¯
        print("\nè§‚å¯Ÿé…ç½®å±æ€§:")
        pprint(obs_config.__dict__)
        print("\n")
        
        # åˆ›å»ºç¯å¢ƒ - ä¿®æ”¹ä¸ºæœ«ç«¯ä½å§¿æ§åˆ¶å’Œå¤¹çˆªä½ç½®æ§åˆ¶
        self.env = Environment(
            action_mode=MoveArmThenGripper(
                arm_action_mode=EndEffectorPoseViaPlanning(),  # æ”¹ä¸ºæœ«ç«¯ä½å§¿æ§åˆ¶
                gripper_action_mode=GripperJointPosition(absolute_mode=True)), 
            obs_config=obs_config, 
            headless=False)  # ä½¿ç”¨é»˜è®¤æœºå™¨äººè®¾ç½®
        
        # å¯åŠ¨ç¯å¢ƒ
        self.env.launch()
        print("RLBenchç¯å¢ƒå·²å¯åŠ¨")
    
    def load_task(self, task_name):
        """
        åŠ è½½æŒ‡å®šçš„ä»»åŠ¡
        
        Args:
            task_name: ä»»åŠ¡ç±»åç§°
        """
        try:
            module = importlib.import_module('rlbench.tasks')
            task_class = getattr(module, task_name)
            self.task = self.env.get_task(task_class)
            print(f"å·²åŠ è½½ä»»åŠ¡: {task_name}")
            return True
        except (ImportError, AttributeError) as e:
            print(f"åŠ è½½ä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def process_observation(self, obs):
        """
        å¤„ç†RLBenchè§‚å¯Ÿå¯¹è±¡ä¸ºACTæ¨¡å‹å¯ç”¨çš„æ ¼å¼
        
        Args:
            obs: RLBenchè§‚å¯Ÿå¯¹è±¡
            
        Returns:
            imgdata: åŒ…å«å›¾åƒçš„å­—å…¸
            robot_state: æœºå™¨äººçŠ¶æ€ï¼ˆå…³èŠ‚ä½ç½®å’Œå¤¹çˆªçŠ¶æ€ï¼‰
        """
        # æå–å›¾åƒæ•°æ®
        imgdata = {}
        if hasattr(obs, 'wrist_rgb') and obs.wrist_rgb is not None and 'wrist_camera' in self.camera_names:
            imgdata['wrist_camera'] = obs.wrist_rgb
            
        if hasattr(obs, 'front_rgb') and obs.front_rgb is not None and 'front_camera' in self.camera_names:
            imgdata['front_camera'] = obs.front_rgb
            
        if hasattr(obs, 'left_shoulder_rgb') and obs.left_shoulder_rgb is not None and 'left_shoulder_camera' in self.camera_names:
            imgdata['left_shoulder_camera'] = obs.left_shoulder_rgb
            
        if hasattr(obs, 'right_shoulder_rgb') and obs.right_shoulder_rgb is not None and 'right_shoulder_camera' in self.camera_names:
            imgdata['right_shoulder_camera'] = obs.right_shoulder_rgb
            
        if hasattr(obs, 'overhead_rgb') and obs.overhead_rgb is not None and 'overhead_camera' in self.camera_names:
            imgdata['overhead_camera'] = obs.overhead_rgb
        
        import copy
        # æå–æœºå™¨äººçŠ¶æ€
        robot_state = list(copy.deepcopy(obs.gripper_pose))  # å…³èŠ‚ä½ç½®
        robot_state.append(copy.deepcopy(obs.gripper_open))  # å¤¹çˆªçŠ¶æ€ï¼ˆ1=å…³é—­ï¼Œ0=æ‰“å¼€ï¼‰
        
        return imgdata, robot_state
    


    def run_task(self, task_name, max_steps=1000):
        """
        æ‰§è¡ŒæŒ‡å®šä»»åŠ¡
        
        Args:
            task_name: è¦æ‰§è¡Œçš„ä»»åŠ¡åç§°
            max_steps: æœ€å¤§æ‰§è¡Œæ­¥æ•°
            
        Returns:
            success: ä»»åŠ¡æ˜¯å¦æˆåŠŸå®Œæˆ
        """
        try:
            # è®¾ç½®ç¯å¢ƒ
            self.setup_environment()
            
            # åŠ è½½ä»»åŠ¡
            if not self.load_task(task_name):
                return False
            
            # é‡ç½®ä»»åŠ¡è·å–åˆå§‹è§‚å¯Ÿ
            descriptions, obs = self.task.reset()
            print(f"ä»»åŠ¡æè¿°: {descriptions}")
            
            # æ‰§è¡Œæ§åˆ¶å¾ªç¯
            success = False
            for step in tqdm(range(max_steps), desc="ä»»åŠ¡æ‰§è¡Œ"):
                # å¤„ç†è§‚å¯Ÿè·å–å›¾åƒå’ŒçŠ¶æ€
                imgdata, robot_state = self.process_observation(obs)
                
                # ä½¿ç”¨ACTæ¨¡å‹è·å–åŠ¨ä½œ
                actaction = self.act_policy.get_actions(imgdata, robot_state)
                
                # æ¨¡å‹è¾“å‡ºè½¬æ¢ä¸ºæœ«ç«¯ä½å§¿æ§åˆ¶
                # æ¨¡å‹è¾“å‡ºçš„å‰7ä¸ªå€¼ä½œä¸ºä½ç½®å’Œå››å…ƒæ•° [x, y, z, qx, qy, qz, qw]
                end_effector_pose = actaction[0:7].copy()  # é¿å…åŸåœ°ä¿®æ”¹ actaction

                # å•ä½åŒ–å››å…ƒæ•°
                quat = end_effector_pose[3:7]
                norm = np.linalg.norm(quat)
                if norm < 1e-6:
                    # é»˜è®¤ä½¿ç”¨å•ä½å››å…ƒæ•°ï¼Œé¿å…é™¤ä»¥é›¶
                    quat = np.array([0.0, 0.0, 0.0, 1.0])
                else:
                    quat = quat / norm
                end_effector_pose[3:7] = quat


                # å¤¹çˆªæ§åˆ¶ - ä»äºŒå€¼è½¬æ¢ä¸ºè¿ç»­å€¼
                gripper_value = actaction[7]
                
                # å°†å¤¹çˆªå€¼è½¬æ¢ä¸ºå…³èŠ‚ä½ç½® (0-0.04èŒƒå›´)
                # å¦‚æœæ¨¡å‹è¾“å‡ºæ˜¯äºŒå€¼çš„ï¼Œå¤§äº0.5è¡¨ç¤ºå…³é—­(æ¥è¿‘0.04)ï¼Œå°äº0.5è¡¨ç¤ºæ‰“å¼€(æ¥è¿‘0)
                gripper_joint_position = 0.04 * float(gripper_value > 0.5)
                
                # æ‰§è¡ŒåŠ¨ä½œ
                try:
                    # åˆå¹¶æœ«ç«¯ä½å§¿å’Œå¤¹çˆªå…³èŠ‚ä½ç½®
                    action = np.concatenate([end_effector_pose, [gripper_joint_position]]).astype(np.float32)
                    obs, reward, terminate = self.task.step(action)

                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æˆåŠŸå®Œæˆ
                    if reward == 1.0:
                        print("\nğŸ‰ ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ!")
                        success = True
                        break
                    
                    if terminate:
                        print("\nâŒ ä»»åŠ¡è¢«ç»ˆæ­¢")
                        break
                        
                except Exception as e:
                    print(f"\næ‰§è¡ŒåŠ¨ä½œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    break
            
            print(f"\nä»»åŠ¡æ‰§è¡Œç»“æŸ. {'æˆåŠŸ' if success else 'æœªæˆåŠŸ'}")
            return success
            
        except Exception as e:
            print(f"ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
        
        finally:
            # å…³é—­ç¯å¢ƒ
            if self.env is not None:
                self.env.shutdown()
                print("RLBenchç¯å¢ƒå·²å…³é—­")
    
    def cleanup_memory(self):
        """
        æ¸…ç†å†…å­˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šæ¬¡ä»»åŠ¡æ‰§è¡Œä¹‹é—´
        """
        if self.env is not None:
            self.env.shutdown()
            self.env = None
            self.task = None
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        print("å†…å­˜å·²æ¸…ç†")


def main():
    """ä¸»å‡½æ•°ï¼Œä»é…ç½®æ–‡ä»¶åŠ è½½æ‰€æœ‰å‚æ•°"""

    rootpath = pathlib.Path(__file__).parent
    file_yaml = rootpath.joinpath('config_act_eval.yaml') 
    
    parser = argparse.ArgumentParser(description='ACT RLBenchæ§åˆ¶å™¨')
    parser.add_argument('--config', type=str, default=file_yaml,
                        help='ACTé…ç½®æ–‡ä»¶è·¯å¾„')
    args = parser.parse_args()
    
    # ä»é…ç½®æ–‡ä»¶è¯»å–æ‰€æœ‰å‚æ•°
    with open(args.config, 'r') as f:
        config = yaml.safe_load(f)
    
    # ä»é…ç½®æ–‡ä»¶è¯»å–ä»»åŠ¡åç§°å’Œæœ€å¤§æ­¥æ•°
    task_name = config.get('taskclassname', 'OpenDrawer')
    max_steps = config.get('max_steps', 1000)
    
    print(f"ä»é…ç½®æ–‡ä»¶åŠ è½½ä»»åŠ¡: {task_name}")
    
    # åˆ›å»ºæ§åˆ¶å™¨
    controller = RLBenchACTController(args.config)
    
    # æ‰§è¡Œä»»åŠ¡
    success = controller.run_task(
        task_name=task_name,
        max_steps=max_steps
    )
    
    # æ¸…ç†å†…å­˜
    controller.cleanup_memory()
    
    # è¿”å›ç»“æœä»£ç 
    return 0 if success else 1


if __name__ == "__main__":
    main()