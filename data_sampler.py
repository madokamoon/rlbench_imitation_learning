import numpy as np
import os
from pprint import pprint
import yaml
import importlib
import json
import pathlib
from PIL import Image
import time, datetime
from tqdm import tqdm 
import random
import torch

from rlbench.action_modes.action_mode import MoveArmThenGripper
from rlbench.action_modes.arm_action_modes import JointVelocity, EndEffectorPoseViaPlanning
from rlbench.action_modes.gripper_action_modes import GripperJointPosition
from rlbench.environment import Environment
from rlbench.observation_config import ObservationConfig
from act_policy_wrapper import ACTPolicyWrapper


class RLBenchProcessor:
    """ç”¨äºRLBenchç¯å¢ƒçš„æ•°æ®é‡‡æ ·ä¸è½¨è¿¹æ‰§è¡Œçš„ç»¼åˆå¤„ç†å™¨"""
    
    def __init__(self, config_path='data_sampler.yaml'):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        # åŠ è½½é…ç½®
        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)
 
        # ä»é…ç½®ä¸­è·å–å‚æ•°
        self.save_path_head = self.config.get('save_path_head')
        self.save_path_end = self.config.get('save_path_end')
        self.taskname = self.config.get('taskname')
        self.num_demos = self.config.get('num_demos')
        self.image_width = self.config['image']['width']
        self.image_height = self.config['image']['height']
        self.camera_names = self.config['cameras']
        self.camera_names_forward = self.config['act_policy']['task_config']['camera_names']
        
        # ç¡®å®šè¿è¡Œæ¨¡å¼ (é‡‡æ · or ååº”)
        self.mode = self.config.get('mode', 0)
        print(f"å½“å‰æ¨¡å¼: {self.mode} (0=é‡‡æ ·, 1=è½¨è¿¹å¤ç°, 2=è¯„ä¼°)")
        if self.mode == 1:
            self.data_path = self.config['data_path']
        elif self.mode == 2:
            self.act_policy = ACTPolicyWrapper(self.config.get('act_policy'))


        # åˆå§‹åŒ–ç¯å¢ƒå’Œä»»åŠ¡ç›¸å…³å˜é‡
        self.env = None
        self.task = None
        self.obs_config = None

    def _check_and_make(self, directory):
        """åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
        if not os.path.exists(directory):
            os.makedirs(directory)
            
    def _check_path_exists(self, directory):
        """æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨"""
        if not os.path.exists(directory):
            raise FileNotFoundError(f"è·¯å¾„ä¸å­˜åœ¨: {directory}")
        return True

    def _create_observation_config(self):
        """åˆ›å»ºè§‚æµ‹é…ç½®"""
        obs_config = ObservationConfig()

        cameras_dict = {
            'front_camera': obs_config.front_camera,
            'wrist_camera': obs_config.wrist_camera,
            'left_shoulder_camera': obs_config.left_shoulder_camera,
            'right_shoulder_camera': obs_config.right_shoulder_camera,
            'overhead_camera': obs_config.overhead_camera
        }

        # å…ˆå…³é—­æ‰€æœ‰ç›¸æœº
        for camera in cameras_dict.values():
            camera.rgb = False
            camera.depth = False
            camera.mask = False

        # åªå¯ç”¨é…ç½®ä¸­æŒ‡å®šçš„ç›¸æœº
        for camera_name in self.camera_names:
            if camera_name in cameras_dict:
                cameras_dict[camera_name].rgb = True
                cameras_dict[camera_name].depth = True
                cameras_dict[camera_name].mask = True
                cameras_dict[camera_name].depth_in_meters = True  # å°†æ·±åº¦å­˜å‚¨ä¸º 0-1 å½’ä¸€åŒ–å€¼
                cameras_dict[camera_name].masks_as_one_channel = True  # å°†æ©ç å­˜å‚¨ä¸ºå•é€šé“å›¾åƒ
                cameras_dict[camera_name].image_size = (self.image_width, self.image_height)

        # è®¾ç½®å…¶ä»–è§‚æµ‹å‚æ•°
        obs_config.joint_positions = True
        obs_config.joint_velocities = True
        obs_config.gripper_open = True
        obs_config.gripper_pose = True 
        obs_config.gripper_joint_positions = True
        obs_config.gripper_matrix = True
        obs_config.gripper_touch_forces = False
        # obs_config.record_gripper_closing = True  # ä¼šå¡å¾ˆä¹…
          
        return obs_config

    def task_file_to_task_class(self, task_file):
        class_name = ''.join([w[0].upper() + w[1:] for w in task_file.split('_')])
        mod = importlib.import_module("rlbench.tasks.%s" % task_file)
        mod = importlib.reload(mod)
        task_class = getattr(mod, class_name)
        return task_class,class_name

    def setup_environment(self):
        """è®¾ç½®å¹¶å¯åŠ¨RLBenchç¯å¢ƒ"""
        # åˆ›å»ºè§‚æµ‹é…ç½®
        self.obs_config = self._create_observation_config()
        
        # æ‰“å°è§‚æµ‹é…ç½®ä¿¡æ¯
        print("\n ObservationConfig å±æ€§:")
        pprint(self.obs_config.__dict__)
        print("\n")
        
        print("è®¾ç½®RLBenchç¯å¢ƒ...")
        
        # æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„æ§åˆ¶æ–¹å¼
        if self.mode == 1 or self.mode == 2:
            # ååº”æ¨¡å¼ï¼šä½¿ç”¨æœ«ç«¯ä½å§¿æ§åˆ¶
            action_mode = MoveArmThenGripper(
                arm_action_mode=EndEffectorPoseViaPlanning(),
                gripper_action_mode=GripperJointPosition(absolute_mode=True))
            print("ä½¿ç”¨æœ«ç«¯ä½å§¿æ§åˆ¶æ¨¡å¼è¿›è¡Œè½¨è¿¹æ‰§è¡Œ")
        elif self.mode == 0:
            # é‡‡æ ·æ¨¡å¼ï¼šä½¿ç”¨å…³èŠ‚é€Ÿåº¦æ§åˆ¶
            action_mode = MoveArmThenGripper(
                arm_action_mode=JointVelocity(),
                gripper_action_mode=GripperJointPosition(absolute_mode=True))
            print("ä½¿ç”¨å…³èŠ‚é€Ÿåº¦æ§åˆ¶æ¨¡å¼è¿›è¡Œæ•°æ®é‡‡æ ·")
            
        # åˆ›å»ºå¹¶é…ç½®RLBenchç¯å¢ƒ
        self.env = Environment(
            action_mode=action_mode,
            obs_config=self.obs_config, 
            headless=False,
            # static_positions=True,
        )
            
        self.env.launch()
        print("ç¯å¢ƒå¯åŠ¨æˆåŠŸ")

    def load_task(self):
        """åŠ è½½æŒ‡å®šçš„ä»»åŠ¡"""
        print(f"åŠ è½½ä»»åŠ¡: {self.taskname}")
        task_class,classname = self.task_file_to_task_class(self.taskname)
        print(f"åŠ è½½ä»»åŠ¡ç±»: {classname}")
        self.task = self.env.get_task(task_class)
        print("ä»»åŠ¡åŠ è½½æˆåŠŸ")

    def save_demo_raw(self, demo, example_path, ex_idx):
        """
        ä¿å­˜æ¼”ç¤ºæ•°æ®ä¸ºåŸå§‹çš„PNGå’ŒJSONæ ¼å¼
        
        Args:
            demo: æ¼”ç¤ºæ•°æ®
            example_path: ä¿å­˜è·¯å¾„
            ex_idx: ç¤ºä¾‹ç´¢å¼•
        """
        # åˆ›å»ºç¤ºä¾‹æ–‡ä»¶å¤¹
        episode_folder = pathlib.Path(example_path).joinpath(f"{ex_idx}")
        episode_folder.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºç›¸æœºæ–‡ä»¶å¤¹
        for cam_name in self.camera_names:
            camera_folder = episode_folder.joinpath(cam_name)
            camera_folder_depth = episode_folder.joinpath(cam_name+"_depth")
            camera_folder_mask = episode_folder.joinpath(cam_name+"_mask")
            camera_folder.mkdir(parents=True, exist_ok=True)
            camera_folder_depth.mkdir(parents=True, exist_ok=True)
            camera_folder_mask.mkdir(parents=True, exist_ok=True)

        
        # åˆå§‹åŒ–æ•°æ®å­˜å‚¨
        state_data = {}
        
        # ä½¿ç”¨tqdmä¸ºå¾ªç¯æ·»åŠ è¿›åº¦æ¡
        for i, obs in tqdm(enumerate(demo), total=len(demo), desc=f"æ¼”ç¤º {ex_idx} å¤„ç†è¿›åº¦"):
            # è·å–å½“å‰æ—¶é—´æˆ³
            current_timestamp = time.time()
            
            # ä¿å­˜ä¸Šä¸€å¸§çš„åŠ¨ä½œæ•°æ®
            if i > 0:
                # å¯¹äºGripperJointPosition, å°†å¤¹çˆªå¼€åˆåº¦è½¬æ¢ä¸ºå…³èŠ‚ä½ç½®
                prev_frame_data['grasp_action'] = [obs.gripper_open]
                prev_frame_data['robot_joint_action'] = obs.joint_positions.tolist()
                prev_frame_data['robot_action'] = obs.gripper_pose.tolist()
                state_data[str(i-1)] = prev_frame_data

            # å½“å‰å¸§çš„çŠ¶æ€æ•°æ®
            frame_data = {
                'timestamp': current_timestamp,
                'grasp_state': [obs.gripper_open],
                'gripper_joint_positions': obs.gripper_joint_positions.tolist() if obs.gripper_joint_positions is not None else None,
                'robot_joint_state': obs.joint_positions.tolist(),
                'robot_joint_vel': obs.joint_velocities.tolist() if obs.joint_velocities is not None else None,
                'robot_state': obs.gripper_pose.tolist(),
                'robot_state_matrix': obs.gripper_matrix.tolist() if obs.gripper_matrix is not None else None,
            }

            prev_frame_data = frame_data

            # æœ€åä¸€å¸§ä¹Ÿéœ€è¦ä¿å­˜åŠ¨ä½œ
            if i == len(demo) - 1:
                frame_data['grasp_action'] = [obs.gripper_open]
                frame_data['robot_joint_action'] = obs.joint_positions.tolist()
                frame_data['robot_action'] = obs.gripper_pose.tolist()
                state_data[str(i)] = frame_data

            # ä½¿ç”¨å­—å…¸æ˜ å°„ç›¸æœºå±æ€§ååˆ°è§‚æµ‹å¯¹è±¡çš„å±æ€§
            camera_mapping = {
                'front_camera': {
                    'rgb': 'front_rgb',
                    'depth': 'front_depth',
                    'mask': 'front_mask'
                },
                'wrist_camera': {
                    'rgb': 'wrist_rgb',
                    'depth': 'wrist_depth',
                    'mask': 'wrist_mask'
                },
                'left_shoulder_camera': {
                    'rgb': 'left_shoulder_rgb',
                    'depth': 'left_shoulder_depth',
                    'mask': 'left_shoulder_mask'
                },
                'right_shoulder_camera': {
                    'rgb': 'right_shoulder_rgb',
                    'depth': 'right_shoulder_depth',
                    'mask': 'right_shoulder_mask'
                },
                'overhead_camera': {
                    'rgb': 'overhead_rgb',
                    'depth': 'overhead_depth',
                    'mask': 'overhead_mask'
                }
            }

            # éå†æ‰€æœ‰ç›¸æœº
            for camera_name in self.camera_names:
                if camera_name not in camera_mapping:
                    continue

                # ä¿å­˜RGBå›¾åƒ
                rgb_attr = camera_mapping[camera_name]['rgb']
                rgb_img = getattr(obs, rgb_attr, None)
                # print("rgb_img.shape",rgb_img.shape)
                if rgb_img is not None:
                    rgb_path = episode_folder.joinpath(camera_name, f"{i}.png")
                    Image.fromarray(rgb_img).save(str(rgb_path))

                # ä¿å­˜æ·±åº¦å›¾åƒ
                depth_attr = camera_mapping[camera_name]['depth']
                depth_img = getattr(obs, depth_attr, None)
                # print("depth_img.shape",depth_img.shape)
                if depth_img is not None:
                    depth_path = episode_folder.joinpath(f"{camera_name}_depth", f"{i}.png")
                    depth_image = np.clip(depth_img * 100, 0, 255).astype(np.uint8)
                    Image.fromarray(depth_image).save(str(depth_path))

                # ä¿å­˜æ©ç å›¾åƒ
                mask_attr = camera_mapping[camera_name]['mask']
                mask_img = getattr(obs, mask_attr, None)
                # print("mask_img.shape",mask_img.shape)

                if mask_img is not None:


                    # å¤„ç†æ©ç å›¾åƒ
                    # åˆ›å»ºç©ºç™½RGBå›¾åƒ
                    mask_array = mask_img
                    rgb_array = np.zeros((mask_array.shape[0], mask_array.shape[1], 3), dtype=np.uint8)
                    
                    # æ ¹æ®ç°åº¦å€¼è®¾ç½®ä¸åŒçš„RGBå€¼
                    rgb_array[(mask_array == 35) | (mask_array == 31) | (mask_array == 34) , 0] = 255
                    rgb_array[mask_array == 84, 1] = 255
                    rgb_array[mask_array == 83, 2] = 255

                    mask_path = episode_folder.joinpath(f"{camera_name}_mask", f"{i}.png")
                    mask_image = np.clip(rgb_array, 0, 255).astype(np.uint8)
                    Image.fromarray(mask_image).save(str(mask_path))




        
        # ä¿å­˜çŠ¶æ€æ•°æ®åˆ°JSONæ–‡ä»¶
        state_json_path = episode_folder.joinpath("state.json")
        with open(str(state_json_path), 'w') as json_file:
            json.dump(state_data, json_file, indent=4)
        
        print(f"æ¼”ç¤º {ex_idx} åŸå§‹æ•°æ®ä¿å­˜æˆåŠŸï¼Œè·¯å¾„: {episode_folder}")

    def collect_and_save_demos(self):
        """é€ä¸ªæ”¶é›†ã€ä¿å­˜demoï¼Œå¹¶åœ¨æ¯ä¸ªdemoå¤„ç†å®Œåé‡Šæ”¾å†…å­˜"""
        import gc  # å¯¼å…¥åƒåœ¾å›æ”¶æ¨¡å—

        # åˆ›å»ºä¿å­˜è·¯å¾„
        task_path = os.path.join(self.save_path_head, self.taskname)

        if self.save_path_end == "":
            now_time = datetime.datetime.now()
            str_time = now_time.strftime("%Y-%m-%d-%H-%M-%S")
            variation_path = os.path.join(task_path, str_time) 
            self.save_path_end = str_time
        else:
            variation_path = os.path.join(task_path, self.save_path_end)

        self._check_and_make(variation_path)

        # é€ä¸ªæ”¶é›†å’Œä¿å­˜demo
        for i in range(self.num_demos):
            print(f'æ”¶é›†å’Œä¿å­˜æ¼”ç¤º {i}/{self.num_demos}')
            
            # åªè·å–ä¸€ä¸ªdemo
            demo = self.task.get_demos(1, live_demos=True)[0]
            
            # ä¿å­˜è¿™ä¸ªdemo
            self.save_demo_raw(demo, variation_path, i)
            
            # æ˜¾å¼é‡Šæ”¾å†…å­˜
            del demo
            gc.collect()  

        print(f'æ•°æ®é›†å·²ä¿å­˜åˆ° {variation_path}')

    def load_trajectory(self, trajectory_path):
        """
        ä»æŒ‡å®šè·¯å¾„åŠ è½½è½¨è¿¹æ•°æ®
        
        Args:
            trajectory_path: è½¨è¿¹æ•°æ®è·¯å¾„
            
        Returns:
            dict: åŠ è½½çš„è½¨è¿¹æ•°æ®
        """
        state_file_path = os.path.join(trajectory_path, 'state.json')
        print(f"åŠ è½½è½¨è¿¹æ•°æ®: {state_file_path}")
        
        with open(state_file_path, 'r') as f:
            trajectory_data = json.load(f)
            
        print(f"æˆåŠŸåŠ è½½è½¨è¿¹ï¼Œå…±æœ‰ {len(trajectory_data)} ä¸ªæ•°æ®ç‚¹")
        return trajectory_data

    def execute_trajectory(self, trajectory_data, epoch_idx):
        """
        æ‰§è¡Œè½¨è¿¹æ§åˆ¶
        
        Args:
            trajectory_data: åŒ…å«æœºæ¢°è‡‚è½¨è¿¹çš„å­—å…¸
            epoch_idx: å½“å‰epochçš„ç´¢å¼•
        """
        # é‡ç½®ä»»åŠ¡
        print("é‡ç½®ä»»åŠ¡...")
        descriptions, obs = self.task.reset()
        print("ä»»åŠ¡æè¿°: ", descriptions)
        
        # æŒ‰é¡ºåºæ‰§è¡Œè½¨è¿¹
        print(f"å¼€å§‹æ‰§è¡Œè½¨è¿¹ (Epoch {epoch_idx})...")
        trajectory_keys = sorted([int(k) for k in trajectory_data.keys()])
        
        for t in tqdm(trajectory_keys, desc=f"Epoch {epoch_idx} æ‰§è¡Œè¿›åº¦"):
            frame_data = trajectory_data[str(t)]
            
            # æå–æœ«ç«¯ä½å§¿å’Œå¤¹çˆªåŠ¨ä½œ
            pose = frame_data['robot_state']  # [x, y, z, qx, qy, qz, qw]
            
            # è·å–å¤¹çˆªå¼€åˆçŠ¶æ€ (0-1èŒƒå›´)
            gripper_open = frame_data.get('grasp_state', [0])[0]
            
            # å¦‚æœgrasp_actionä¸æ˜¯0-1èŒƒå›´(æ˜¯0-0.04)ï¼Œéœ€è¦å½’ä¸€åŒ–
            if gripper_open > 0 and gripper_open <= 0.04:
                gripper_joint_position = gripper_open  # å·²ç»æ˜¯å…³èŠ‚ä½ç½®
            else:
                # GripperJointPositionéœ€è¦å°†0-1èŒƒå›´æ˜ å°„åˆ°0-0.04èŒƒå›´
                gripper_joint_position = gripper_open * 0.04
            
            # æ‰§è¡ŒåŠ¨ä½œ
            action = np.array(pose + [gripper_joint_position])
            obs, reward, terminate = self.task.step(action)
            
            # ç®€çŸ­æš‚åœä»¥ä¾¿è§‚å¯Ÿ
            # time.sleep(0.01)
            
            if terminate:
                print(f"Epoch {epoch_idx} ä»»åŠ¡ç»“æŸ")
                break
                
        print(f"è½¨è¿¹ {epoch_idx} æ‰§è¡Œå®Œæˆ")
        
        # ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œè§‚å¯Ÿæœ€ç»ˆçŠ¶æ€
        time.sleep(1)

    def eval_process_observation(self, obs):

        # æå–å›¾åƒæ•°æ®
        imgdata = {}


        # ä½¿ç”¨å­—å…¸æ˜ å°„ç›¸æœºå±æ€§ååˆ°è§‚æµ‹å¯¹è±¡çš„å±æ€§
        camera_mapping = {
            'front_camera': {
                'rgb': 'front_rgb',
                'depth': 'front_depth',
                'mask': 'front_mask'
            },
            'wrist_camera': {
                'rgb': 'wrist_rgb',
                'depth': 'wrist_depth',
                'mask': 'wrist_mask'
            },
            'left_shoulder_camera': {
                'rgb': 'left_shoulder_rgb',
                'depth': 'left_shoulder_depth',
                'mask': 'left_shoulder_mask'
            },
            'right_shoulder_camera': {
                'rgb': 'right_shoulder_rgb',
                'depth': 'right_shoulder_depth',
                'mask': 'right_shoulder_mask'
            },
            'overhead_camera': {
                'rgb': 'overhead_rgb',
                'depth': 'overhead_depth',
                'mask': 'overhead_mask'
            }
        }

        # éå†æ‰€æœ‰ç›¸æœº
        for camera_name in self.camera_names:
            if camera_name not in camera_mapping:
                continue

            # ä¿å­˜RGBå›¾åƒ
            rgb_attr = camera_mapping[camera_name]['rgb']
            rgb_img = getattr(obs, rgb_attr, None)
            imgdata[camera_name] = rgb_img

            # ä¿å­˜æ©ç å›¾åƒ
            mask_attr = camera_mapping[camera_name]['mask']
            mask_img = getattr(obs, mask_attr, None)

            # å¤„ç†æ©ç å›¾åƒ
            # åˆ›å»ºç©ºç™½RGBå›¾åƒ
            mask_array = mask_img
            rgb_array = np.zeros((mask_array.shape[0], mask_array.shape[1], 3), dtype=np.uint8)
            
            # æ ¹æ®ç°åº¦å€¼è®¾ç½®ä¸åŒçš„RGBå€¼
            rgb_array[(mask_array == 35) | (mask_array == 31) | (mask_array == 34) , 0] = 255
            rgb_array[mask_array == 84, 1] = 255
            rgb_array[mask_array == 83, 2] = 255

            imgdata[f"{camera_name}_mask"] = rgb_array


        import copy
        # æå–æœºå™¨äººçŠ¶æ€
        robot_state = list(obs.joint_positions)  # å…³èŠ‚ä½ç½®
        robot_state.append(float(1 - obs.gripper_open))  # å¤¹çˆªçŠ¶æ€ï¼ˆ1=å…³é—­ï¼Œ0=æ‰“å¼€ï¼‰
        robot_state = list(copy.deepcopy(obs.gripper_pose))  # å…³èŠ‚ä½ç½®
        robot_state.append(copy.deepcopy(obs.gripper_open))  # å¤¹çˆªçŠ¶æ€ï¼ˆ1=å…³é—­ï¼Œ0=æ‰“å¼€ï¼‰

        return imgdata, robot_state

    def act_eval(self, max_steps=250, max_attempts=100):
        """
        æ‰§è¡ŒæŒ‡å®šä»»åŠ¡ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•ï¼Œå¹¶ç»Ÿè®¡æˆåŠŸç‡å’Œå¹³å‡æ­¥éª¤æ•°
        
        Args:
            max_steps: æ¯æ¬¡å°è¯•çš„æœ€å¤§æ‰§è¡Œæ­¥æ•°
            max_attempts: æœ€å¤§å°è¯•æ¬¡æ•°

        Returns:
            tuple: (æˆåŠŸç‡, å¹³å‡æ­¥éª¤æ•°)
        """
        from weight import calculate_change_weight  # å¯¼å…¥è®¡ç®—æƒé‡çš„å‡½æ•°
        
        success_counts = 0  # æˆåŠŸæ¬¡æ•°ç»Ÿè®¡
        successful_steps = []  # è®°å½•æ¯æ¬¡æˆåŠŸå°è¯•çš„æ­¥éª¤æ•°
        attempt = 0
        
        try:
            while attempt < max_attempts:
                attempt += 1
                print(f"\nå¼€å§‹ç¬¬ {attempt}/{max_attempts} æ¬¡å°è¯•æ‰§è¡Œä»»åŠ¡")
                
                # é‡ç½®ä»»åŠ¡è·å–åˆå§‹è§‚å¯Ÿ
                descriptions, obs = self.task.reset()
                self.act_policy.reset()
                print(f"ä»»åŠ¡æè¿°: {descriptions}")
                
                # ç”¨äºå­˜å‚¨ä¸Šä¸€å¸§çš„å›¾åƒ
                prev_images = None
                
                # æ‰§è¡Œæ§åˆ¶å¾ªç¯
                success_in_this_attempt = False
                for step in tqdm(range(max_steps), desc=f"ç¬¬ {attempt} æ¬¡å°è¯•"):
                    # å¤„ç†è§‚å¯Ÿè·å–å›¾åƒå’ŒçŠ¶æ€
                    imgdata, robot_state = self.eval_process_observation(obs)
                    print(f"æœºå™¨äººçŠ¶æ€: {robot_state}")

                    # è®¡ç®—æƒé‡view_weights
                    view_weights = []
                    if prev_images is not None:
                        print("è®¡ç®—è§†è§’å˜åŒ–æƒé‡ï¼š")
                        for cam_name in self.camera_names_forward:
                            if cam_name in imgdata:
                                curr_img = imgdata[f"{cam_name}_mask"]
                                prev_img = prev_images[f"{cam_name}_mask"]
                                # è®¡ç®—å˜åŒ–æƒé‡
                                weight = calculate_change_weight(prev_img, curr_img)
                                view_weights.append(weight)
                                print(f"  - {cam_name}: {weight:.4f}")
                    
                    # å¦‚æœæœ‰è®¡ç®—å‡ºæƒé‡ï¼Œåˆ™ä½¿ç”¨å®ƒä»¬ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤æƒé‡
                    if view_weights and len(view_weights) == len(self.camera_names_forward):
                        # å½’ä¸€åŒ–æƒé‡ï¼Œç¡®ä¿æ€»å’Œä¸ºç›¸æœºæ•°é‡ï¼ˆå¹³å‡æƒé‡ä¸º1ï¼‰
                        total_weight = sum(view_weights)
                        norm_view_weights = [w * len(view_weights) / total_weight for w in view_weights]
                        print(f"å½’ä¸€åŒ–è§†è§’æƒé‡: {[f'{w:.4f}' for w in norm_view_weights]}")
                        actaction = self.act_policy.get_actions(imgdata, robot_state, view_weights=norm_view_weights)
                    else:
                        print("ä½¿ç”¨é»˜è®¤è§†è§’æƒé‡")
                        actaction = self.act_policy.get_actions(imgdata, robot_state)

                    # ä¿å­˜å½“å‰å¸§ä½œä¸ºä¸‹ä¸€æ¬¡è¿­ä»£çš„ä¸Šä¸€å¸§
                    # prev_images = {}
                    # for cam_name in self.camera_names_forward:
                    #     if cam_name in imgdata:
                    #         prev_images[f"{cam_name}_mask"] = imgdata[f"{cam_name}_mask"].copy()

                    # æ¨¡å‹è¾“å‡ºè½¬æ¢ä¸ºæœ«ç«¯ä½å§¿æ§åˆ¶
                    end_effector_pose = actaction[0:7].copy()
                    
                    # å•ä½åŒ–å››å…ƒæ•°
                    quat = end_effector_pose[3:7]
                    norm = np.linalg.norm(quat)
                    if norm < 1e-6:
                        quat = np.array([0.0, 0.0, 0.0, 1.0])
                    else:
                        quat = quat / norm
                    end_effector_pose[3:7] = quat

                    # å¤¹çˆªæ§åˆ¶
                    gripper_value = actaction[7]
                    gripper_joint_position = 0.04 * float(gripper_value > 0.5)

                    # æ‰§è¡ŒåŠ¨ä½œ
                    try:
                        action = np.concatenate([end_effector_pose, [gripper_joint_position]]).astype(np.float32)
                        print(f"æ‰§è¡ŒåŠ¨ä½œ: {action}")
                        obs, reward, terminate = self.task.step(action)

                        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                        if reward == 1.0:
                            print(f"\nğŸ‰ ç¬¬ {attempt} æ¬¡å°è¯•ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ! ä½¿ç”¨æ­¥éª¤: {step+1}")
                            success_counts += 1
                            successful_steps.append(step+1)  # è®°å½•æˆåŠŸæ‰€éœ€çš„æ­¥éª¤æ•°
                            success_in_this_attempt = True
                            break

                        if terminate:
                            print(f"\nâŒ ç¬¬ {attempt} æ¬¡å°è¯•è¢«ç»ˆæ­¢")
                            break

                    except Exception as e:
                        print(f"\nç¬¬ {attempt} æ¬¡å°è¯•æ‰§è¡ŒåŠ¨ä½œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
                        break
                
                if not success_in_this_attempt and attempt < max_attempts:
                    print(f"\nç¬¬ {attempt} æ¬¡å°è¯•æœªæˆåŠŸï¼Œå°†é‡æ–°å°è¯•")
                    time.sleep(1)
            
            # è®¡ç®—ç»Ÿè®¡ç»“æœ
            success_rate = success_counts / attempt if attempt > 0 else 0
            avg_steps = sum(successful_steps) / len(successful_steps) if successful_steps else 0
            
            print(f"\n===== è¯„ä¼°ç»“æœç»Ÿè®¡ =====")
            print(f"- æ€»å°è¯•æ¬¡æ•°: {attempt}")
            print(f"- æˆåŠŸæ¬¡æ•°: {success_counts}")
            print(f"- æˆåŠŸç‡: {success_rate:.2%}")
            print(f"- å¹³å‡æˆåŠŸæ­¥éª¤æ•°: {avg_steps:.2f}")
            if successful_steps:
                print(f"- æœ€å°‘æ­¥éª¤æ•°: {min(successful_steps)}")
                print(f"- æœ€å¤šæ­¥éª¤æ•°: {max(successful_steps)}")
            
            return success_rate, avg_steps

        except Exception as e:
            print(f"ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return 0, 0

        finally:
            # åªåœ¨æ‰€æœ‰å°è¯•ç»“æŸåå…³é—­ç¯å¢ƒ
            if self.env is not None and attempt >= max_attempts:
                self.env.shutdown()
                print("RLBenchç¯å¢ƒå·²å…³é—­")

    def process_all_epochs(self):
        """å¤„ç†æ‰€æœ‰çš„epochï¼ˆéå†æ•°æ®æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹ï¼‰"""
        print(f"å¤„ç†æ¥è‡ªè·¯å¾„çš„æ‰€æœ‰è½¨è¿¹: {self.data_path}")
        
        # æ£€æŸ¥åŸºç¡€è·¯å¾„æ˜¯å¦å­˜åœ¨
        self._check_path_exists(self.data_path)
        
        # è·å–æ‰€æœ‰å­æ–‡ä»¶å¤¹ï¼ˆepochï¼‰
        epoch_folders = []
        for item in os.listdir(self.data_path):
            item_path = os.pathè·¯å¾„.join(self.data_path, item)
            # åªå¤„ç†æ–‡ä»¶å¤¹ä¸”ç¡®ä¿æœ‰state.jsonæ–‡ä»¶
            if os.path.isdir(item_path) and os.path.exists(os.path.join(item_path, 'state.json')):
                epoch_folders.append(item)
        
        # ç¡®ä¿æŒ‰ç…§ç¼–å·æ’åº
        epoch_folders = sorted(epoch_folders, key=lambda x: int(x) if x.isdigit() else float('inf'))
        
        if not epoch_folders:
            print(f"è­¦å‘Š: åœ¨ {self.data_path} ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„è½¨è¿¹æ•°æ®")
            return
            
        print(f"æ‰¾åˆ° {len(epoch_folders)} ä¸ªè½¨è¿¹")
        
        # éå†æ‰§è¡Œæ¯ä¸ªepoch
        for epoch in epoch_folders:
            epoch_path = os.path.join(self.data_path, epoch)
            print(f"\nå¤„ç†è½¨è¿¹: {epoch_path}")
            
            # åŠ è½½è½¨è¿¹
            trajectory_data = self.load_trajectory(epoch_path)
            
            # æ‰§è¡Œè½¨è¿¹
            self.execute_trajectory(trajectory_data, epoch)
            
            # ç­‰å¾…çŸ­æš‚æ—¶é—´ï¼Œå‡†å¤‡ä¸‹ä¸€ä¸ªè½¨è¿¹
            time.sleep(0.5)

    def run(self):
        """è¿è¡Œå¤„ç†å™¨ï¼Œæ ¹æ®é…ç½®å†³å®šæ˜¯æ•°æ®é‡‡æ ·è¿˜æ˜¯è½¨è¿¹æ‰§è¡Œ"""
        try:
            self.setup_environment()
            self.load_task()
            
            if self.mode == 1:
                print("ä»¥è½¨è¿¹å¤ç°æ¨¡å¼è¿è¡Œ...")
                self.process_all_epochs()
            elif self.mode == 0:
                print("ä»¥æ•°æ®é‡‡æ ·æ¨¡å¼è¿è¡Œ...")
                self.collect_and_save_demos()
            elif self.mode == 2:
                print("ä»¥è¯„ä¼°æ¨¡å¼è¿è¡Œ...")
                self.act_eval()
                
        finally:
            if self.env is not None:
                self.env.shutdown()
                print("ç¯å¢ƒå·²å…³é—­")


if __name__ == "__main__":
    # åˆ›å»ºå¹¶è¿è¡Œå¤„ç†å™¨

    # åœ¨ç¨‹åºå¼€å§‹å¤„æ·»åŠ 
    seed = int(time.time()) # ä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºç§å­
    np.random.seed(seed)
    random.seed(seed)
    print(f"ä½¿ç”¨éšæœºç§å­: {seed}")

    processor = RLBenchProcessor()
    processor.run()


